{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019dd07c",
   "metadata": {},
   "source": [
    "### 本文件展示学习 RNN 的全流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e9766a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   review sentiment\n",
      "0      One of the other reviewers has mentioned that ...  positive\n",
      "1      A wonderful little production. <br /><br />The...  positive\n",
      "2      I thought this was a wonderful way to spend ti...  positive\n",
      "3      Basically there's a family where a little boy ...  negative\n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "...                                                  ...       ...\n",
      "49995  I thought this movie did a down right good job...  positive\n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
      "49997  I am a Catholic taught in parochial elementary...  negative\n",
      "49998  I'm going to have to disagree with the previou...  negative\n",
      "49999  No one expects the Star Trek movies to be high...  negative\n",
      "\n",
      "[50000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集 IMDb 电影评论情感分类\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./data/IMDB Dataset.csv')\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdb09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的RNN网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vs, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vs, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn = nn.RNNCell(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):  # x: (batch_size, seq_len)\n",
    "        batch_size, seq_len = x.size()\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "\n",
    "        h_t = torch.zeros(batch_size, self.hidden_dim, device=x.device)\n",
    "        for t in range(seq_len):\n",
    "            x_t = embedded[:, t, :]\n",
    "            h_t = self.rnn(x_t, h_t)\n",
    "\n",
    "        output = self.fc(h_t)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce151b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(90, 50)\n",
       "  (rnn): RNNCell(50, 64)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(vs=90, embedding_dim=50, hidden_dim=64, output_dim=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836c203d",
   "metadata": {},
   "source": [
    "### 数据处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c73691fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "def build_vocab(sentences, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        tokens = tokenize(sent)\n",
    "        counter.update(tokens)\n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "def encode_sentence(sentence, vocab, max_len):\n",
    "    tokens = tokenize(sentence)\n",
    "    ids = [vocab.get(token, vocab['<unk>']) for token in tokens[:max_len]]\n",
    "    ids += [vocab['<pad>']] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "def load_data(path, vocab=None, max_len=100, test_size=0.2, seed=42):\n",
    "    df = pd.read_csv(path)\n",
    "    sentences = df['review'].tolist()\n",
    "    raw_labels = df['sentiment'].tolist()\n",
    "    label_map = {'positive': 1.0, 'negative': 0.0}\n",
    "    labels = [label_map[label.strip().lower()] for label in raw_labels]\n",
    "\n",
    "    # 划分训练/测试\n",
    "    s_train, s_test, y_train, y_test = train_test_split(\n",
    "        sentences, labels, test_size=test_size, random_state=seed\n",
    "    )\n",
    "\n",
    "    if vocab is None:\n",
    "        vocab = build_vocab(s_train)  # 只用训练集构建词表\n",
    "\n",
    "    # 编码文本\n",
    "    x_train = [encode_sentence(s, vocab, max_len) for s in s_train]\n",
    "    x_test = [encode_sentence(s, vocab, max_len) for s in s_test]\n",
    "\n",
    "    return (\n",
    "        torch.tensor(x_train), torch.tensor(y_train).float(),\n",
    "        torch.tensor(x_test), torch.tensor(y_test).float(),\n",
    "        vocab\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e33a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集: torch.Size([40000, 50]) torch.Size([40000])\n",
      "测试集: torch.Size([10000, 50]) torch.Size([10000])\n",
      "词表大小: 57766\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 加载数据\n",
    "x_train, y_train, x_test, y_test, vocab = load_data('./data/IMDB Dataset.csv', max_len=50)\n",
    "vocab[\"<pad>\"] = 0\n",
    "vocab[\"<unk>\"] = 1\n",
    "print(\"训练集:\", x_train.shape, y_train.shape)\n",
    "print(\"测试集:\", x_test.shape, y_test.shape)\n",
    "print(\"词表大小:\", len(vocab))\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2032882",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "814f4365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 1250/1250 [00:46<00:00, 27.16it/s, loss=0.673, acc=52.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.6928 Train Accuracy: 52.66\n",
      "[Epoch 1] Test Accuracy: 52.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 1250/1250 [00:47<00:00, 26.52it/s, loss=0.693, acc=56.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.6803 Train Accuracy: 56.37\n",
      "[Epoch 2] Test Accuracy: 54.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 1250/1250 [00:47<00:00, 26.40it/s, loss=0.746, acc=59.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 0.6682 Train Accuracy: 59.12\n",
      "[Epoch 3] Test Accuracy: 57.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 1250/1250 [00:47<00:00, 26.38it/s, loss=0.569, acc=63.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 0.6386 Train Accuracy: 63.90\n",
      "[Epoch 4] Test Accuracy: 62.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 1250/1250 [00:51<00:00, 24.24it/s, loss=0.586, acc=65.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 0.6251 Train Accuracy: 65.21\n",
      "[Epoch 5] Test Accuracy: 55.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 1250/1250 [00:50<00:00, 24.51it/s, loss=0.677, acc=61.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 0.6503 Train Accuracy: 61.26\n",
      "[Epoch 6] Test Accuracy: 60.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 1250/1250 [00:48<00:00, 25.97it/s, loss=0.602, acc=66.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 0.6140 Train Accuracy: 66.68\n",
      "[Epoch 7] Test Accuracy: 65.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 1250/1250 [00:47<00:00, 26.33it/s, loss=0.699, acc=70.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 0.5726 Train Accuracy: 70.75\n",
      "[Epoch 8] Test Accuracy: 69.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 1250/1250 [00:53<00:00, 23.33it/s, loss=0.56, acc=76.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 0.5074 Train Accuracy: 76.34\n",
      "[Epoch 9] Test Accuracy: 68.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 1250/1250 [00:57<00:00, 21.81it/s, loss=0.511, acc=79.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 0.4663 Train Accuracy: 79.15\n",
      "[Epoch 10] Test Accuracy: 70.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 1250/1250 [01:07<00:00, 18.47it/s, loss=0.324, acc=81.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 0.4316 Train Accuracy: 81.23\n",
      "[Epoch 11] Test Accuracy: 71.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 1250/1250 [00:53<00:00, 23.17it/s, loss=0.48, acc=82.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 0.4108 Train Accuracy: 82.71\n",
      "[Epoch 12] Test Accuracy: 71.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 1250/1250 [00:46<00:00, 27.07it/s, loss=0.558, acc=75.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 0.5036 Train Accuracy: 75.57\n",
      "[Epoch 13] Test Accuracy: 59.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 1250/1250 [00:46<00:00, 26.93it/s, loss=0.469, acc=81.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 0.4265 Train Accuracy: 81.55\n",
      "[Epoch 14] Test Accuracy: 71.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 1250/1250 [00:46<00:00, 27.05it/s, loss=0.396, acc=84.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 0.3840 Train Accuracy: 84.16\n",
      "[Epoch 15] Test Accuracy: 66.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 1250/1250 [00:45<00:00, 27.17it/s, loss=0.524, acc=77.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train Loss: 0.4722 Train Accuracy: 77.62\n",
      "[Epoch 16] Test Accuracy: 62.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 1250/1250 [00:58<00:00, 21.55it/s, loss=0.332, acc=82.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train Loss: 0.4116 Train Accuracy: 82.20\n",
      "[Epoch 17] Test Accuracy: 70.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 1250/1250 [01:06<00:00, 18.93it/s, loss=0.265, acc=83.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train Loss: 0.3841 Train Accuracy: 83.89\n",
      "[Epoch 18] Test Accuracy: 72.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 1250/1250 [01:02<00:00, 20.03it/s, loss=0.375, acc=84.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train Loss: 0.3642 Train Accuracy: 84.85\n",
      "[Epoch 19] Test Accuracy: 71.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 1250/1250 [00:52<00:00, 23.85it/s, loss=0.304, acc=87.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train Loss: 0.3241 Train Accuracy: 87.47\n",
      "[Epoch 20] Test Accuracy: 71.54\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 初始化模型\n",
    "model = RNN(vs=len(vocab), embedding_dim=50, hidden_dim=64, output_dim=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 20\n",
    "\n",
    "# 训练过程\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    train_tot = 0\n",
    "    train_correct = 0\n",
    "    for batch_x, batch_y in loop:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        logits = model(batch_x).squeeze(1)  # shape: (batch,)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_correct += (preds == batch_y).sum().item()\n",
    "        train_tot += batch_y.size(0)\n",
    "        loop.set_postfix({\n",
    "                \"loss\": loss.item(),\n",
    "                \"acc\": 100*train_correct / train_tot if train_tot else 0\n",
    "            })\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {total_loss/len(train_loader):.4f} Train Accuracy: {train_correct/train_tot*100:.2f}\")\n",
    "\n",
    "    # --- 测试评估 ---\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_test_batch, y_test_batch in test_loader:\n",
    "            x_test_batch, y_test_batch = x_test_batch.to(device), y_test_batch.to(device)\n",
    "            logits = model(x_test_batch).squeeze(1)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > 0.5).float()\n",
    "            correct += (preds == y_test_batch).sum().item()\n",
    "            total += y_test_batch.size(0)\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), 'RNN_IMDB.pth')\n",
    "    print(f\"[Epoch {epoch+1}] Test Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54c5ff",
   "metadata": {},
   "source": [
    "### 测试 RNN 的情感分析性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "599c7f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I absolutely loved this movie!\n",
      "Prediction: negative (Confidence: 0.3479)\n",
      "--------------------------------------------------\n",
      "Text: This film was a masterpiece, beautifully acted and directed.\n",
      "Prediction: positive (Confidence: 0.9609)\n",
      "--------------------------------------------------\n",
      "Text: Great performance by the lead actor, I would watch it again.\n",
      "Prediction: positive (Confidence: 0.9609)\n",
      "--------------------------------------------------\n",
      "Text: I hated every minute of this film.\n",
      "Prediction: negative (Confidence: 0.0545)\n",
      "--------------------------------------------------\n",
      "Text: Terrible plot and wooden acting.\n",
      "Prediction: negative (Confidence: 0.0545)\n",
      "--------------------------------------------------\n",
      "Text: One of the worst movies I’ve ever seen.\n",
      "Prediction: negative (Confidence: 0.0545)\n",
      "--------------------------------------------------\n",
      "Text: The story made no sense and the pacing was awful.\n",
      "Prediction: negative (Confidence: 0.0545)\n",
      "--------------------------------------------------\n",
      "Text: The visuals were great, but the plot was lacking.\n",
      "Prediction: negative (Confidence: 0.3479)\n",
      "--------------------------------------------------\n",
      "Text: It was okay, not bad but not amazing either.\n",
      "Prediction: negative (Confidence: 0.3479)\n",
      "--------------------------------------------------\n",
      "Text: I expected more, but it wasn't the worst.\n",
      "Prediction: negative (Confidence: 0.3479)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiments(texts, vocab, model, device, max_len=100):\n",
    "    model.eval()\n",
    "    for text in texts:\n",
    "        tokens = text.lower().split()\n",
    "        token_ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "        if len(token_ids) < max_len:\n",
    "            token_ids += [vocab[\"<pad>\"]] * (max_len - len(token_ids))\n",
    "        else:\n",
    "            token_ids = token_ids[:max_len]\n",
    "        input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids).squeeze(1)\n",
    "            prob = torch.sigmoid(logits)\n",
    "            label = \"positive\" if prob.item() >= 0.5 else \"negative\"\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Prediction: {label} (Confidence: {prob.item():.4f})\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 示例测试文本\n",
    "test_texts = [\n",
    "    \"I absolutely loved this movie!\",\n",
    "    \"This film was a masterpiece, beautifully acted and directed.\",\n",
    "    \"Great performance by the lead actor, I would watch it again.\",\n",
    "    \"I hated every minute of this film.\",\n",
    "    \"Terrible plot and wooden acting.\",\n",
    "    \"One of the worst movies I’ve ever seen.\",\n",
    "    \"The story made no sense and the pacing was awful.\",\n",
    "    \"The visuals were great, but the plot was lacking.\",\n",
    "    \"It was okay, not bad but not amazing either.\",\n",
    "    \"I expected more, but it wasn't the worst.\",\n",
    "]\n",
    "model = RNN(vs=len(vocab), embedding_dim=50, hidden_dim=64, output_dim=1).to(device)\n",
    "model.load_state_dict(torch.load('RNN_IMDB.pth', map_location=device))\n",
    "# 执行预测\n",
    "predict_sentiments(test_texts, vocab, model, device, max_len=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
